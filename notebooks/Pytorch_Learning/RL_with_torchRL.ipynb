{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch._C._dynamo.guards'; 'torch._C._dynamo' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensordict\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TensorDictModule\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensordict\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NormalParamExtractor\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n",
      "File \u001b[0;32m~/anaconda3/envs/machinelearning/lib/python3.12/site-packages/tensordict/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Meta Platforms, Inc. and affiliates.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# This source code is licensed under the MIT license found in the\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensordict\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_reductions\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensordict\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lazy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyStackedTensorDict\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensordict\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_nestedkey\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NestedKey\n",
      "File \u001b[0;32m~/anaconda3/envs/machinelearning/lib/python3.12/site-packages/tensordict/_reductions.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmultiprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m reduction\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensordict\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lazy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyStackedTensorDict\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensordict\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_td\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TensorDict\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensordict\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorclass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NonTensorData\n",
      "File \u001b[0;32m~/anaconda3/envs/machinelearning/lib/python3.12/site-packages/tensordict/_lazy.py:37\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdist\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensordict\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmemmap\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MemoryMappedTensor\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dim \u001b[38;5;28;01mas\u001b[39;00m ftdim\n",
      "File \u001b[0;32m~/anaconda3/envs/machinelearning/lib/python3.12/site-packages/tensordict/memmap.py:22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensordict\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _shape, implement_for, IndexType, NESTED_TENSOR_ERR\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMemoryMappedTensor\u001b[39;00m(torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m     26\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"A Memory-mapped Tensor.\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m    Supports filenames or file handlers.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03m          ...     memmap_tensor = MemoryMappedTensor.ones_like(tensor, filename=file.name)\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/machinelearning/lib/python3.12/site-packages/tensordict/utils.py:2609\u001b[0m\n\u001b[1;32m   2598\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_lock_warn\u001b[39m():\n\u001b[1;32m   2599\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2600\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing lock_() in a compiled graph should \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2601\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly be done if users make sure that the code runs in eager mode. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2605\u001b[0m         category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m   2606\u001b[0m     )\n\u001b[0;32m-> 2609\u001b[0m _lock_warn \u001b[38;5;241m=\u001b[39m \u001b[43massume_constant_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_lock_warn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_inbuild\u001b[39m():\n\u001b[1;32m   2613\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39minline_inbuilt_nn_modules:\n",
      "File \u001b[0;32m~/anaconda3/envs/machinelearning/lib/python3.12/site-packages/torch/compiler/__init__.py:83\u001b[0m, in \u001b[0;36massume_constant_result\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mallow_in_graph\u001b[39m(fn):\n\u001b[1;32m     44\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;03m    Tells the compiler frontend (Dynamo) to skip symbolic introspection of the function\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m    and instead directly write it to the graph when encountered.\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m    If you are using :func:`torch.compile` (with backend=\"inductor\" (the default)), or\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    :func:`torch.export.export`, and trying to black-box a Python function throughout\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m    all tracing, do not use this API.\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03m    Instead, please create a custom operator (see :ref:`custom-ops-landing-page`)\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m    .. warning::\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m        If you're a typical torch.compile user (e.g. you're applying torch.compile to\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m        a model to make it run faster), you probably don't want to use this function.\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03m        :func:`allow_in_graph` is a footgun because it skips the compiler frontend\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03m        (Dynamo) that is responsible for doing safety checks (graph breaks, handling\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m        closures, etc). Incorrect usage will lead to difficult-to-debug silent\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m        incorrectness issues.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;03m    Given a Python function with no allow_in_graph decorator, regular execution\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03m    of torch.compile traces through the function. :func:`allow_in_graph` changes\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03m    it so that the frontend does not trace inside the function, but the compiler\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    backend still traces through it. Compare this to custom operators, which\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m    treats a function as a black box throughout the torch.compile stack. The following\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m    table compares these mechanisms.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m    +------------------------+-----------------------+--------------------------------+\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    | Mechanism              | Frontend (Dynamo)     | Backend (AOTAutograd+Inductor) |\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    +========================+=======================+================================+\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m    | no decorator           | trace inside          | trace inside                   |\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m    +------------------------+-----------------------+--------------------------------+\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m    | allow_in_graph         | opaque callable       | trace inside                   |\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03m    +------------------------+-----------------------+--------------------------------+\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;03m    | custom op              | opaque callable       | opaque callable                |\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;03m    +------------------------+-----------------------+--------------------------------+\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03m    One common use case for :func:`allow_in_graph()` is as an escape hatch for the compiler\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;124;03m    frontend: if you know the function works w.r.t. to the downstream components of the\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;124;03m    compilation stack (AOTAutograd and Inductor) but there is a Dynamo bug that prevents it from\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m    symbolically introspecting the function properly (or if your code is in C/C++ and\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m \u001b[38;5;124;03m    therefore cannot be introspected with Dynamo), then one can decorate said function\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m    with :func:`allow_in_graph` to bypass Dynamo.\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m    We require that ``fn`` adhere to the following restrictions. Failure to adhere\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m    results in undefined behavior:\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03m    - The inputs to ``fn`` must be Proxy-able types in the FX graph. Valid types include:\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m      Tensor/int/bool/float/None/List[Tensor?]/List[int?]/List[float?]\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m      Tuple[Tensor?, ...]/Tuple[int?, ...]/Tuple[float?, ...]/torch.dtype/torch.device\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03m    - The outputs to ``fn`` must be Proxy-able types in the FX graph (see previous bullet)\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m    - all Tensors used inside of ``fn`` must be passed directly as inputs to ``fn``\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m      (as opposed to being captured variables).\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;124;03m        fn: A callable representing the function to be included in the graph.\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m            If ``fn`` is a list or tuple of callables it recursively applies\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m            :func:`allow_in_graph()` to each function and returns a new list or\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m            tuple containing the modified functions.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m    Example::\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m        torch.compiler.allow_in_graph(my_custom_function)\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m        @torch.compile(...)\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03m        def fn(a):\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m            x = torch.add(x, 1)\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m            x = my_custom_function(x)\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;124;03m            x = torch.add(x, 1)\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03m            return x\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m        fn(...)\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \n\u001b[1;32m    115\u001b[0m \u001b[38;5;124;03m    Will capture a single graph containing ``my_custom_function()``.\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mallow_in_graph(fn)\n",
      "File \u001b[0;32m~/anaconda3/envs/machinelearning/lib/python3.12/site-packages/torch/_dynamo/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_frame, eval_frame, resume_execution\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m callback_handler, on_compile_end, on_compile_start\n",
      "File \u001b[0;32m~/anaconda3/envs/machinelearning/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_logging\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mguards\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GlobalStateGuard\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_compile_pg\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CompileTimeInstructionCounter\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch._C._dynamo.guards'; 'torch._C._dynamo' is not a package"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from torch import multiprocessing\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tensordict.nn import TensorDictModule\n",
    "from tensordict.nn.distributions import NormalParamExtractor\n",
    "from torch import nn\n",
    "from torchrl.collectors import SyncDataCollector\n",
    "from torchrl.data.replay_buffers import ReplayBuffer\n",
    "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
    "from torchrl.data.replay_buffers.storages import LazyTensorStorage\n",
    "from torchrl.envs import (Compose, DoubleToFloat, ObservationNorm, StepCounter,\n",
    "                          TransformedEnv)\n",
    "from torchrl.envs.libs.gym import GymEnv\n",
    "from torchrl.envs.utils import check_env_specs, ExplorationType, set_exploration_type\n",
    "from torchrl.modules import ProbabilisticActor, TanhNormal, ValueOperator\n",
    "from torchrl.objectives import ClipPPOLoss\n",
    "from torchrl.objectives.value import GAE\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchrl\n",
      "  Downloading torchrl-0.6.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (39 kB)\n",
      "Collecting torch>=2.5.0 (from torchrl)\n",
      "  Downloading torch-2.5.1-cp312-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: numpy in /Users/stevenyu/anaconda3/envs/machinelearning/lib/python3.12/site-packages (from torchrl) (1.26.4)\n",
      "Requirement already satisfied: packaging in /Users/stevenyu/anaconda3/envs/machinelearning/lib/python3.12/site-packages (from torchrl) (24.1)\n",
      "Requirement already satisfied: cloudpickle in /Users/stevenyu/anaconda3/envs/machinelearning/lib/python3.12/site-packages (from torchrl) (3.1.0)\n",
      "Collecting tensordict>=0.6.0 (from torchrl)\n",
      "  Downloading tensordict-0.6.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (8.9 kB)\n",
      "Collecting orjson (from tensordict>=0.6.0->torchrl)\n",
      "  Downloading orjson-3.10.12-cp312-cp312-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (41 kB)\n",
      "Requirement already satisfied: filelock in /Users/stevenyu/anaconda3/envs/machinelearning/lib/python3.12/site-packages (from torch>=2.5.0->torchrl) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/stevenyu/anaconda3/envs/machinelearning/lib/python3.12/site-packages (from torch>=2.5.0->torchrl) (4.11.0)\n",
      "Requirement already satisfied: networkx in /Users/stevenyu/anaconda3/envs/machinelearning/lib/python3.12/site-packages (from torch>=2.5.0->torchrl) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/stevenyu/anaconda3/envs/machinelearning/lib/python3.12/site-packages (from torch>=2.5.0->torchrl) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/stevenyu/anaconda3/envs/machinelearning/lib/python3.12/site-packages (from torch>=2.5.0->torchrl) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in /Users/stevenyu/anaconda3/envs/machinelearning/lib/python3.12/site-packages (from torch>=2.5.0->torchrl) (75.1.0)\n",
      "Collecting sympy==1.13.1 (from torch>=2.5.0->torchrl)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/stevenyu/anaconda3/envs/machinelearning/lib/python3.12/site-packages (from sympy==1.13.1->torch>=2.5.0->torchrl) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/stevenyu/anaconda3/envs/machinelearning/lib/python3.12/site-packages (from jinja2->torch>=2.5.0->torchrl) (2.1.3)\n",
      "Downloading torchrl-0.6.0-cp312-cp312-macosx_11_0_arm64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m-:--:--\u001b[0m\n",
      "\u001b[?25hDownloading tensordict-0.6.2-cp312-cp312-macosx_11_0_arm64.whl (668 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m668.9/668.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.5.1-cp312-none-macosx_11_0_arm64.whl (63.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.10.12-cp312-cp312-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (248 kB)\n",
      "Installing collected packages: sympy, orjson, torch, tensordict, torchrl\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.2\n",
      "    Uninstalling sympy-1.13.2:\n",
      "      Successfully uninstalled sympy-1.13.2\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.3.0\n",
      "    Uninstalling torch-2.3.0:\n",
      "      Successfully uninstalled torch-2.3.0\n",
      "Successfully installed orjson-3.10.12 sympy-1.13.1 tensordict-0.6.2 torch-2.5.1 torchrl-0.6.0\n",
      "zsh:1: no matches found: gym[mujoco]\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.67.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torchrl\n",
    "!pip3 install gym[mujoco]\n",
    "!pip3 install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
